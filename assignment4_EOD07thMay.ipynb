{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4be09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: html5lib in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (1.1)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (4.19.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\nallag\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pinging google.com [2404:6800:4007:82c::200e] with 32 bytes of data:\n",
      "Reply from 2404:6800:4007:82c::200e: time=12ms \n",
      "Reply from 2404:6800:4007:82c::200e: time=11ms \n",
      "Reply from 2404:6800:4007:82c::200e: time=12ms \n",
      "Reply from 2404:6800:4007:82c::200e: time=12ms \n",
      "\n",
      "Ping statistics for 2404:6800:4007:82c::200e:\n",
      "    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),\n",
      "Approximate round trip times in milli-seconds:\n",
      "    Minimum = 11ms, Maximum = 12ms, Average = 11ms\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib\n",
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!ping google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51f15c2",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank B) Name C) Artist D) Upload date E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f035c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c33b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3dfddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07bc80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options = chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60e678bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: List of most-viewed YouTube videos - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d4f74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video details : ['\"Baby Shark Dance\"[7]', '\"Despacito\"[10]', '\"Johny Johny Yes Papa\"[18]', '\"Bath Song\"[19]', '\"Shape of You\"[20]', '\"See You Again\"[23]', '\"Wheels on the Bus\"[28]', '\"Phonics Song with Two Words\"[29]', '\"Uptown Funk\"[30]', '\"Gangnam Style\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[36]', '\"Dame Tu Cosita\"[37]', '\"Masha and the Bear – Recipe for Disaster\"[38]', '\"Axel F\"[39]', '\"Sugar\"[40]', '\"Baa Baa Black Sheep\"[41]', '\"Counting Stars\"[42]', '\"Lakdi Ki Kathi\"[43]', '\"Roar\"[44]', '\"Waka Waka (This Time for Africa)\"[45]', '\"Sorry\"[46]', '\"Shree Hanuman Chalisa\"[47]', '\"Humpty the train on a fruits ride\"[48]', '\"Thinking Out Loud\"[49]', '\"Perfect\"[50]', '\"Dark Horse\"[51]', '\"Let Her Go\"[52]', '\"Faded\"[53]', '\"Girls Like You\"[54]', '\"Lean On\"[55]']\n",
      "uploader details : [\"Pinkfong Baby Shark - Kids' Songs & Stories\", 'Luis Fonsi', \"LooLoo Kids - Nursery Rhymes and Children's Songs\", 'Cocomelon - Nursery Rhymes', 'Ed Sheeran', 'Wiz Khalifa', 'Cocomelon - Nursery Rhymes', 'ChuChu TV Nursery Rhymes & Kids Songs', 'Mark Ronson', 'Psy', 'Miroshka TV', 'Ultra Records', 'Get Movies', 'Crazy Frog', 'Maroon 5', 'Cocomelon - Nursery Rhymes', 'OneRepublic', 'Jingle Toons', 'Katy Perry', 'Shakira', 'Justin Bieber', 'T-Series Bhakti Sagar', 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs', 'Ed Sheeran', 'Ed Sheeran', 'Katy Perry', 'Passenger', 'Alan Walker', 'Maroon 5', 'Major Lazer Official']\n",
      "views_Billions ['14.32', '8.41', '6.89', '6.66', '6.23', '6.22', '6.01', '5.75', '5.18', '5.10', '5.09', '4.59', '4.57', '4.45', '4.02', '4.01', '4.00', '3.98', '3.98', '3.89', '3.78', '3.77', '3.76', '3.75', '3.70', '3.70', '3.64', '3.60', '3.58', '3.57']\n",
      "Vedio Date  ['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'May 2, 2018', 'January 30, 2017', 'April 6, 2015', 'May 24, 2018', 'March 6, 2014', 'November 19, 2014', 'July 15, 2012', 'February 27, 2018', 'April 5, 2018', 'January 31, 2012', 'June 16, 2009', 'January 14, 2015', 'June 25, 2018', 'May 31, 2013', 'June 14, 2018', 'September 5, 2013', 'June 4, 2010', 'October 22, 2015', 'May 10, 2011', 'January 26, 2018', 'October 7, 2014', 'November 9, 2017', 'February 20, 2014', 'July 25, 2012', 'December 3, 2015', 'May 31, 2018', 'March 22, 2015']\n"
     ]
    }
   ],
   "source": [
    "Video_name = []\n",
    "uploader = []\n",
    "views_Billions = []\n",
    "V_date = []\n",
    "\n",
    "##//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody\n",
    "#//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[10]\n",
    "t_body = driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div[1]/table[1]/tbody')\n",
    "#print(table_body.text) //*[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr[1]\n",
    "\n",
    "for tr in t_body.find_elements(By.XPATH,'.//tr'):\n",
    "    rows = tr.find_elements(By.XPATH, './/td')\n",
    "    #print(rows)\n",
    "    #print(data_vedio)\n",
    "    if len(rows) >=4:\n",
    "        Video_name.append(rows[0].text)\n",
    "        uploader.append(rows[1].text)\n",
    "        views_Billions.append(rows[2].text)\n",
    "        V_date.append(rows[3].text)\n",
    "    #Video_name.append(row)\n",
    "    #uploader.append(row)\n",
    "print(\"video details :\", Video_name)\n",
    "print(\"uploader details :\", uploader)\n",
    "print(\"views_Billions\",views_Billions)\n",
    "print(\"Vedio Date \",V_date)\n",
    "#print(uploader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51806aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Video_name),len(uploader),len(views_Billions),len(V_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d22d0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.DataFrame({\"video details \": Video_name,\"Artist details\":uploader,\"views_Billions\":views_Billions,\"Vedio Date \": V_date})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "616502b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>video details</th>\n",
       "      <th>Artist details</th>\n",
       "      <th>views_Billions</th>\n",
       "      <th>Vedio Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[7]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>14.32</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[10]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.41</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[18]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.89</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"[19]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.66</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"[20]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.23</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[23]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.22</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Wheels on the Bus\"[28]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.01</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Phonics Song with Two Words\"[29]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.75</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[30]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.18</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>5.10</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[36]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>5.09</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.59</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[38]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.57</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Axel F\"[39]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.45</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Sugar\"[40]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>4.02</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>4.01</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>4.00</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.98</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Roar\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.98</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.89</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Sorry\"[46]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.78</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[47]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>3.77</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.76</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Thinking Out Loud\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.75</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.70</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Dark Horse\"[51]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.70</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Let Her Go\"[52]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.64</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Faded\"[53]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.60</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Girls Like You\"[54]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.58</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lean On\"[55]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.57</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking                                   video details   \\\n",
       "0         1                            \"Baby Shark Dance\"[7]   \n",
       "1         2                                  \"Despacito\"[10]   \n",
       "2         3                       \"Johny Johny Yes Papa\"[18]   \n",
       "3         4                                  \"Bath Song\"[19]   \n",
       "4         5                               \"Shape of You\"[20]   \n",
       "5         6                              \"See You Again\"[23]   \n",
       "6         7                          \"Wheels on the Bus\"[28]   \n",
       "7         8                \"Phonics Song with Two Words\"[29]   \n",
       "8         9                                \"Uptown Funk\"[30]   \n",
       "9        10                              \"Gangnam Style\"[31]   \n",
       "10       11  \"Learning Colors – Colorful Eggs on a Farm\"[36]   \n",
       "11       12                             \"Dame Tu Cosita\"[37]   \n",
       "12       13   \"Masha and the Bear – Recipe for Disaster\"[38]   \n",
       "13       14                                     \"Axel F\"[39]   \n",
       "14       15                                      \"Sugar\"[40]   \n",
       "15       16                        \"Baa Baa Black Sheep\"[41]   \n",
       "16       17                             \"Counting Stars\"[42]   \n",
       "17       18                             \"Lakdi Ki Kathi\"[43]   \n",
       "18       19                                       \"Roar\"[44]   \n",
       "19       20           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "20       21                                      \"Sorry\"[46]   \n",
       "21       22                      \"Shree Hanuman Chalisa\"[47]   \n",
       "22       23          \"Humpty the train on a fruits ride\"[48]   \n",
       "23       24                          \"Thinking Out Loud\"[49]   \n",
       "24       25                                    \"Perfect\"[50]   \n",
       "25       26                                 \"Dark Horse\"[51]   \n",
       "26       27                                 \"Let Her Go\"[52]   \n",
       "27       28                                      \"Faded\"[53]   \n",
       "28       29                             \"Girls Like You\"[54]   \n",
       "29       30                                    \"Lean On\"[55]   \n",
       "\n",
       "                                       Artist details views_Billions  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories          14.32   \n",
       "1                                          Luis Fonsi           8.41   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs           6.89   \n",
       "3                          Cocomelon - Nursery Rhymes           6.66   \n",
       "4                                          Ed Sheeran           6.23   \n",
       "5                                         Wiz Khalifa           6.22   \n",
       "6                          Cocomelon - Nursery Rhymes           6.01   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs           5.75   \n",
       "8                                         Mark Ronson           5.18   \n",
       "9                                                 Psy           5.10   \n",
       "10                                        Miroshka TV           5.09   \n",
       "11                                      Ultra Records           4.59   \n",
       "12                                         Get Movies           4.57   \n",
       "13                                         Crazy Frog           4.45   \n",
       "14                                           Maroon 5           4.02   \n",
       "15                         Cocomelon - Nursery Rhymes           4.01   \n",
       "16                                        OneRepublic           4.00   \n",
       "17                                       Jingle Toons           3.98   \n",
       "18                                         Katy Perry           3.98   \n",
       "19                                            Shakira           3.89   \n",
       "20                                      Justin Bieber           3.78   \n",
       "21                              T-Series Bhakti Sagar           3.77   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs           3.76   \n",
       "23                                         Ed Sheeran           3.75   \n",
       "24                                         Ed Sheeran           3.70   \n",
       "25                                         Katy Perry           3.70   \n",
       "26                                          Passenger           3.64   \n",
       "27                                        Alan Walker           3.60   \n",
       "28                                           Maroon 5           3.58   \n",
       "29                               Major Lazer Official           3.57   \n",
       "\n",
       "          Vedio Date   \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9       July 15, 2012  \n",
       "10  February 27, 2018  \n",
       "11      April 5, 2018  \n",
       "12   January 31, 2012  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15      June 25, 2018  \n",
       "16       May 31, 2013  \n",
       "17      June 14, 2018  \n",
       "18  September 5, 2013  \n",
       "19       June 4, 2010  \n",
       "20   October 22, 2015  \n",
       "21       May 10, 2011  \n",
       "22   January 26, 2018  \n",
       "23    October 7, 2014  \n",
       "24   November 9, 2017  \n",
       "25  February 20, 2014  \n",
       "26      July 25, 2012  \n",
       "27   December 3, 2015  \n",
       "28       May 31, 2018  \n",
       "29     March 22, 2015  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns = ['Title', 'Artist', 'Views', 'Release Date'] # and rank \n",
    "#: A) Rank B) Name C) Artist D) Upload date E) Views \n",
    "\n",
    "wiki_df.insert(0,'Ranking', range(1,len(wiki_df) + 1))\n",
    "wiki_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd15aa",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details: A) Series \n",
    "B) Place \n",
    "C) Date \n",
    "D) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dca27068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f01c0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ab4097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n",
    "#print(type(driver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "432004d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title : Official Board of Control for Cricket in India Website\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url_bcci = 'https://www.bcci.tv/'\n",
    "driver.get(url_bcci)\n",
    "print(\"Page title :\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c5a9d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Type: ['4th T20IWomen', '5th T20IWomen', '1st T20IMen', '2nd T20IMen', '3rd T20IMen', '4th T20IMen', '1st T20IMen', '2nd T20IMen', '3rd T20IMen', '4th T20IMen', '5th T20IMen', '1st T20IWomen', '2nd T20IWomen', '3rd T20IWomen', '4th T20IWomen']\n",
      "Series Name: ['INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024', 'INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024', 'ICC MENS T20 WORLD CUP 2024', 'ICC MENS T20 WORLD CUP 2024', 'ICC MENS T20 WORLD CUP 2024', 'ICC MENS T20 WORLD CUP 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'INDIA TOUR OF ZIMBABWE 2024', 'ICC WOMENS T20 WORLD CUP 2024', 'ICC WOMENS T20 WORLD CUP 2024', 'ICC WOMENS T20 WORLD CUP 2024', 'ICC WOMENS T20 WORLD CUP 2024']\n",
      "Date: ['6 MAY, 2024', '9 MAY, 2024', '5 JUNE, 2024', '9 JUNE, 2024', '12 JUNE, 2024', '15 JUNE, 2024', '6 JULY, 2024', '7 JULY, 2024', '10 JULY, 2024', '13 JULY, 2024', '14 JULY, 2024', '4 OCTOBER, 2024', '6 OCTOBER, 2024', '9 OCTOBER, 2024', '13 OCTOBER, 2024']\n",
      "Time: ['3:30 PM IST', '3:30 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '8:00 PM IST', '6:30 PM IST', '6:30 PM IST', '6:30 PM IST', '6:30 PM IST']\n",
      "Location: Sylhet International Cricket Stadium, Sylhet\n",
      "Teams: [['Bangladesh Women', 'India Women'], ['Bangladesh Women', 'India Women'], ['India', 'Ireland'], ['India', 'Pakistan'], ['United States Of America', 'India'], ['Canada', 'India'], ['Zimbabwe', 'India'], ['Zimbabwe', 'India'], ['Zimbabwe', 'India'], ['Zimbabwe', 'India'], ['Zimbabwe', 'India'], ['India Women', 'New Zealand Women'], ['India Women', 'Pakistan Women'], ['India Women', 'Qualifier-1'], ['India Women', 'Australia Women']]\n"
     ]
    }
   ],
   "source": [
    "select_fixtures = driver.find_element(By.XPATH,'//a[@data-element_text=\"Fixtures\"]')\n",
    "select_fixtures.click()\n",
    "time.sleep(5)\n",
    "select_more_matches= driver.find_element(By.XPATH,'//*[@id=\"fixtures\"]/div[2]/div[2]/div/button') #//*[@id=\"fixtures\"]/div[2]/div[2]/div/button\n",
    "driver.execute_script(\"arguments[0].click();\",select_more_matches)\n",
    "\n",
    "\n",
    "Match_details = []\n",
    "series_name = []\n",
    "date_details = []\n",
    "time_details = []\n",
    "location_details = []\n",
    "team_details = []\n",
    "\n",
    "\n",
    "#for page in range(1,3):\n",
    "Fixture_elements = driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]')  \n",
    "    \n",
    "for element in Fixture_elements:\n",
    "    Fixture_series=element.text.strip().split('\\n')\n",
    "    #print(Fixture_series)\n",
    "    if Fixture_series:\n",
    "        Match = Fixture_series[0]\n",
    "        Match_details.append(Match)\n",
    "        series = Fixture_series[1]\n",
    "        series_name.append(series)\n",
    "        date_1 = Fixture_series[2]\n",
    "        date_details.append(date_1)\n",
    "        time_1 = Fixture_series[3]\n",
    "        time_details.append(time_1)\n",
    "        location = Fixture_series[4]\n",
    "        location_details.append(location)\n",
    "        team = Fixture_series[5:7]\n",
    "        team_details.append(team)\n",
    "            \n",
    "print(\"Match Type:\", Match_details)\n",
    "print(\"Series Name:\", series_name)\n",
    "print(\"Date:\", date_details)\n",
    "print(\"Time:\", time_details)\n",
    "print(\"Location:\", location)\n",
    "print(\"Teams:\", team_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3d7ea4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 15 15 15 15 15\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_details),len(series_name),len(date_details),len(time_details),len(location_details),len(team_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ae2337a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "BCCI_df = pd.DataFrame({'Match_details':Match_details,'Series_name':series_name,'Date_details':date_details,'Time_details':time_details,'Location_details':location_details,'Team_details':team_details})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4a33ce4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_details</th>\n",
       "      <th>Series_name</th>\n",
       "      <th>Date_details</th>\n",
       "      <th>Time_details</th>\n",
       "      <th>Location_details</th>\n",
       "      <th>Team_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th T20IWomen</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[Bangladesh Women, India Women]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5th T20IWomen</td>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[Bangladesh Women, India Women]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st T20IMen</td>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>[India, Ireland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd T20IMen</td>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>[India, Pakistan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20IMen</td>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>[United States Of America, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4th T20IMen</td>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>[Canada, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st T20IMen</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>[Zimbabwe, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd T20IMen</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>[Zimbabwe, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3rd T20IMen</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>[Zimbabwe, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4th T20IMen</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>[Zimbabwe, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5th T20IMen</td>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>[Zimbabwe, India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1st T20IWomen</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2024</td>\n",
       "      <td>4 OCTOBER, 2024</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[India Women, New Zealand Women]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2nd T20IWomen</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2024</td>\n",
       "      <td>6 OCTOBER, 2024</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[India Women, Pakistan Women]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3rd T20IWomen</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2024</td>\n",
       "      <td>9 OCTOBER, 2024</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[India Women, Qualifier-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4th T20IWomen</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2024</td>\n",
       "      <td>13 OCTOBER, 2024</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>[India Women, Australia Women]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Match_details                                     Series_name  \\\n",
       "0   4th T20IWomen  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1   5th T20IWomen  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2     1st T20IMen                     ICC MENS T20 WORLD CUP 2024   \n",
       "3     2nd T20IMen                     ICC MENS T20 WORLD CUP 2024   \n",
       "4     3rd T20IMen                     ICC MENS T20 WORLD CUP 2024   \n",
       "5     4th T20IMen                     ICC MENS T20 WORLD CUP 2024   \n",
       "6     1st T20IMen                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "7     2nd T20IMen                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8     3rd T20IMen                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "9     4th T20IMen                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "10    5th T20IMen                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "11  1st T20IWomen                   ICC WOMENS T20 WORLD CUP 2024   \n",
       "12  2nd T20IWomen                   ICC WOMENS T20 WORLD CUP 2024   \n",
       "13  3rd T20IWomen                   ICC WOMENS T20 WORLD CUP 2024   \n",
       "14  4th T20IWomen                   ICC WOMENS T20 WORLD CUP 2024   \n",
       "\n",
       "        Date_details Time_details  \\\n",
       "0        6 MAY, 2024  3:30 PM IST   \n",
       "1        9 MAY, 2024  3:30 PM IST   \n",
       "2       5 JUNE, 2024  8:00 PM IST   \n",
       "3       9 JUNE, 2024  8:00 PM IST   \n",
       "4      12 JUNE, 2024  8:00 PM IST   \n",
       "5      15 JUNE, 2024  8:00 PM IST   \n",
       "6       6 JULY, 2024  8:00 PM IST   \n",
       "7       7 JULY, 2024  8:00 PM IST   \n",
       "8      10 JULY, 2024  8:00 PM IST   \n",
       "9      13 JULY, 2024  8:00 PM IST   \n",
       "10     14 JULY, 2024  8:00 PM IST   \n",
       "11   4 OCTOBER, 2024  6:30 PM IST   \n",
       "12   6 OCTOBER, 2024  6:30 PM IST   \n",
       "13   9 OCTOBER, 2024  6:30 PM IST   \n",
       "14  13 OCTOBER, 2024  6:30 PM IST   \n",
       "\n",
       "                                     Location_details  \\\n",
       "0        Sylhet International Cricket Stadium, Sylhet   \n",
       "1        Sylhet International Cricket Stadium, Sylhet   \n",
       "2   Nassau County International Cricket Stadium, N...   \n",
       "3   Nassau County International Cricket Stadium, N...   \n",
       "4   Nassau County International Cricket Stadium, N...   \n",
       "5   Central Broward Park & Broward County Stadium,...   \n",
       "6                          Harare Sports Club, Harare   \n",
       "7                          Harare Sports Club, Harare   \n",
       "8                          Harare Sports Club, Harare   \n",
       "9                          Harare Sports Club, Harare   \n",
       "10                         Harare Sports Club, Harare   \n",
       "11       Sylhet International Cricket Stadium, Sylhet   \n",
       "12       Sylhet International Cricket Stadium, Sylhet   \n",
       "13       Sylhet International Cricket Stadium, Sylhet   \n",
       "14       Sylhet International Cricket Stadium, Sylhet   \n",
       "\n",
       "                         Team_details  \n",
       "0     [Bangladesh Women, India Women]  \n",
       "1     [Bangladesh Women, India Women]  \n",
       "2                    [India, Ireland]  \n",
       "3                   [India, Pakistan]  \n",
       "4   [United States Of America, India]  \n",
       "5                     [Canada, India]  \n",
       "6                   [Zimbabwe, India]  \n",
       "7                   [Zimbabwe, India]  \n",
       "8                   [Zimbabwe, India]  \n",
       "9                   [Zimbabwe, India]  \n",
       "10                  [Zimbabwe, India]  \n",
       "11   [India Women, New Zealand Women]  \n",
       "12      [India Women, Pakistan Women]  \n",
       "13         [India Women, Qualifier-1]  \n",
       "14     [India Women, Australia Women]  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCCI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ce9d1",
   "metadata": {},
   "source": [
    "#Q3 . Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices E) Share(18-19) F) GDP($ billion)\n",
    "\n",
    "#Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5fc7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "947d537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b322e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc866f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title : StatisticsTimes.com | Collection of Statistics and charts\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url_St_INDEco = 'https://www.statisticstimes.com/'\n",
    "driver.get(url_St_INDEco)\n",
    "print(\"Page title :\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7752e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*[@id=\"top\"]/div[2]/div[2]\n",
    "#//*[@id=\"top\"]/div[2]/div[2]/button/i\n",
    "#//*[@id=\"top\"]/div[2]/div[2]/div\n",
    "#//*[@id=\"top\"]/div[2]/div[2]/div/a[3]  //*[@id=\"top\"]/div[2]/div[2]/div/a[3]\n",
    "#/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\n",
    "#/html/body/div[2]/div[2]/div[2]/ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "5e033a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Ad popup found or unable to close it.\n",
      "GDP link not found\n"
     ]
    }
   ],
   "source": [
    "select_INDEco = driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]')\n",
    "driver.execute_script(\"arguments[0].scrollIntoView(true);\",select_INDEco)\n",
    "select_INDEco.click()\n",
    "\n",
    "\n",
    "select_Country= driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]') \n",
    "select_Country.click()\n",
    "\n",
    "try:\n",
    "    ad_close_button = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.ID, \"dismiss-button\")))\n",
    "    ad_close_button.click()\n",
    "    print(\"Advertisement closed successfully.\")\n",
    "except TimeoutException:\n",
    "    print(\"No Ad popup found or unable to close it.\")\n",
    "    \n",
    "try:\n",
    "    select_INC_states = driver.find_element(By.CSS_SELECTOR,'a[href=\"india/indian-states-gdp.php\"]') \n",
    "    select_INC_states.click()\n",
    "except NoSuchElementException:\n",
    "    print(\"GDP link not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4948b2",
   "metadata": {},
   "source": [
    "# Q4.Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/ \n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "6530fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "335a9e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Explore GitHub · GitHub\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "github_url = 'https://github.com/explore/'\n",
    "driver.get(github_url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "c0393ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wandb / openui', 'massgravel / Microsoft-Activation-Scripts', 'HVision-NKU / StoryDiffusion', 'reorproject / reor', 'rasbt / LLMs-from-scratch', 'dev-xo / remix-saas', 'codecrafters-io / build-your-own-x', 'abi / secret-llama', 'Stirling-Tools / Stirling-PDF', 'xM4ddy / OFGB', 'fastfetch-cli / fastfetch', 'KindXiaoming / pykan', 'karpathy / llm.c', 'bepass-org / oblivion-desktop', 'Ryujinx / Ryujinx', 'systemdesign42 / system-design', 'lencx / ChatGPT', 'lmstudio-ai / lms', 'dockur / windows', 'novuhq / novu', 'solana-labs / solana', 'VinciGit00 / Scrapegraph-ai', 'plandex-ai / plandex', 'pagefaultgames / pokerogue']\n",
      "[\"OpenUI let's you describe UI using your imagination, then see it rendered live.\", 'A Windows and Office activator using HWID / Ohook / KMS38 / Online KMS activation methods, with a focus on open-source code and fewer antivirus detections.', 'Create Magic Story!', 'Private & offline AI personal knowledge management app.', 'Implementing a ChatGPT-like LLM from scratch, step by step', 'A Lightweight, Production-Ready Remix Stack for your next SaaS Application.', 'Master programming by recreating your favorite technologies from scratch.', 'Fully private LLM chatbot that runs entirely with a browser with no server needed. Supports Mistral and LLama 3.', '#1 Locally hosted web application that allows you to perform various operations on PDF files', 'GUI Tool To Removes Ads From Various Places Around Windows 11', 'Like neofetch, but much faster because written mostly in C.', 'Kolmogorov Arnold Networks', 'LLM training in simple, raw C/CUDA', 'unofficial desktop version of oblivion', 'Experimental Nintendo Switch Emulator written in C#', 'A resource to help you learn system design.', '🔮 ChatGPT Desktop Application (Mac, Windows and Linux)', 'LM Studio in your terminal', 'Windows in a Docker container.', '🔥 The open-source notification infrastructure with fully functional embedded notification center 🚀🚀🚀', 'Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.', 'Python scraper based on AI', 'An AI coding engine for building complex, real-world software with LLMs']\n",
      "['8', '5', '5', '11', 'N/A', '6', '116', 'N/A', '1', 'N/A', '85', '8', 'N/A', '5', '205', 'N/A', '30', '2', '7', '398', '491', 'N/A', '13', '89']\n"
     ]
    }
   ],
   "source": [
    "#Click the \"Trending\" option\n",
    "#/html/body/div[1]/div[4]/main/div[1]/nav/div/a[3]\n",
    "trending_opt = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div[4]/main/div[1]/nav/div/a[3]')))\n",
    "trending_opt.click()\n",
    "#select \"repository\" Tab \n",
    "#input_d   = input(\"Enter the option Repository/Developers\")\n",
    "#print(\"Option is :\",input_d)\n",
    "#if input_d == 'Repository':\n",
    "repo_tab = WebDriverWait(driver,30).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[1]/nav/a[1]')))\n",
    "repo_tab.click()\n",
    "#else:\n",
    "    #/html/body/div[1]/div[4]/main/div[3]/div/div[1]/nav/a[2]\n",
    "  #  repo_tab = WebDriverWait(driver,30).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[1]/nav/a[2]')))\n",
    "    #repo_tab.click()    \n",
    "\n",
    "#You have to find the following details: \n",
    "#A) Repository title \n",
    "#B) Repository description \n",
    "#C) Contributors count \n",
    "#D) Language used \n",
    "\n",
    "repo_titles = []\n",
    "repo_description = []\n",
    "Contributers = []\n",
    "used_Language = []\n",
    "\n",
    "#/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[1]/h2/a\n",
    "for i in range(1,25):\n",
    "    try:\n",
    "        #repo_elements = driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article['+ str(i)+']/h2/a')\n",
    "#print(repo_elements)\n",
    "        repo_element = WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH,f'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article['+ str(i)+']/h2/a')))\n",
    "    #for repo_element in repo_elements:\n",
    "        repo_title = repo_element.text\n",
    "        repo_titles.append(repo_title)\n",
    "                                                                                       \n",
    "    except StaleElementReferenceException:\n",
    "        print(f\"Element in index {i} is stale\")\n",
    "        continue\n",
    "        \n",
    "print(repo_titles)\n",
    "\n",
    "for i in range(1,25):\n",
    "    repo_descris = driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article['+str(i)+']/p')\n",
    "#print(repo_elements)\n",
    "    for repo_descri in repo_descris:\n",
    "        repo_des = repo_descri.text\n",
    "        repo_description.append(repo_des)\n",
    "    \n",
    "print(repo_description)\n",
    "\n",
    "#/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[1]/h2/a\n",
    "for i in range(1,25):\n",
    "    Contributes_tab = WebDriverWait(driver,30).until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article['+str(i)+']/h2/a')))\n",
    "    Contributes_tab.click()\n",
    "    try:\n",
    "        #//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span\n",
    "        #contributers_count_element  = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.CSS_SELECTOR,'span.Counter.ml-1')))\n",
    "        contributers_count_element = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span')))\n",
    "        contributers_count =  contributers_count_element.text\n",
    "        Contributers.append(contributers_count)\n",
    "        #Lang_count_element = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span')))\n",
    "        #Lang_count =  Lang_count_element.text\n",
    "        #used_Language.append(Lang_count)\n",
    "    except TimeoutException:\n",
    "        try:\n",
    "            contributers_count_element = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span')))\n",
    "            #//*[@id=\"repo-content-pjax-container\"]/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span\n",
    "            contributers_count =  contributers_count_element.text\n",
    "            Contributers.append(contributers_count)\n",
    "        except TimeoutException:\n",
    "            Contributers.append('N/A')\n",
    "\n",
    "    \n",
    "    driver.back()\n",
    "    \n",
    "print(Contributers)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "f2882c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 23, 24)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_titles),len(repo_description),len(Contributers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "78c8d9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(repo_titles),len(repo_description),len(Contributers))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "195489ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "repo_titles_filld = repo_titles + ['_'] * (max_length - len(repo_titles))\n",
    "repo_description_filld = repo_description + ['_'] * (max_length - len(repo_description))\n",
    "Contributers_filld = Contributers + ['_'] * (max_length - len(Contributers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "8c594f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 24)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_titles_filld), len(repo_description_filld),len(Contributers_filld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "666675ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_github = pd.DataFrame({'Repository_titles':repo_titles_filld,'Repository_description':repo_description_filld,'Contributers':Contributers_filld})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "8efc79c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_titles</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wandb / openui</td>\n",
       "      <td>OpenUI let's you describe UI using your imagin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massgravel / Microsoft-Activation-Scripts</td>\n",
       "      <td>A Windows and Office activator using HWID / Oh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HVision-NKU / StoryDiffusion</td>\n",
       "      <td>Create Magic Story!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reorproject / reor</td>\n",
       "      <td>Private &amp; offline AI personal knowledge manage...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rasbt / LLMs-from-scratch</td>\n",
       "      <td>Implementing a ChatGPT-like LLM from scratch, ...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dev-xo / remix-saas</td>\n",
       "      <td>A Lightweight, Production-Ready Remix Stack fo...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codecrafters-io / build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abi / secret-llama</td>\n",
       "      <td>Fully private LLM chatbot that runs entirely w...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stirling-Tools / Stirling-PDF</td>\n",
       "      <td>#1 Locally hosted web application that allows ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xM4ddy / OFGB</td>\n",
       "      <td>GUI Tool To Removes Ads From Various Places Ar...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fastfetch-cli / fastfetch</td>\n",
       "      <td>Like neofetch, but much faster because written...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KindXiaoming / pykan</td>\n",
       "      <td>Kolmogorov Arnold Networks</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>karpathy / llm.c</td>\n",
       "      <td>LLM training in simple, raw C/CUDA</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bepass-org / oblivion-desktop</td>\n",
       "      <td>unofficial desktop version of oblivion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ryujinx / Ryujinx</td>\n",
       "      <td>Experimental Nintendo Switch Emulator written ...</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>systemdesign42 / system-design</td>\n",
       "      <td>A resource to help you learn system design.</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lencx / ChatGPT</td>\n",
       "      <td>🔮 ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lmstudio-ai / lms</td>\n",
       "      <td>LM Studio in your terminal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dockur / windows</td>\n",
       "      <td>Windows in a Docker container.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>novuhq / novu</td>\n",
       "      <td>🔥 The open-source notification infrastructure ...</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>solana-labs / solana</td>\n",
       "      <td>Web-Scale Blockchain for fast, secure, scalabl...</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VinciGit00 / Scrapegraph-ai</td>\n",
       "      <td>Python scraper based on AI</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>plandex-ai / plandex</td>\n",
       "      <td>An AI coding engine for building complex, real...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pagefaultgames / pokerogue</td>\n",
       "      <td>_</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository_titles  \\\n",
       "0                              wandb / openui   \n",
       "1   massgravel / Microsoft-Activation-Scripts   \n",
       "2                HVision-NKU / StoryDiffusion   \n",
       "3                          reorproject / reor   \n",
       "4                   rasbt / LLMs-from-scratch   \n",
       "5                         dev-xo / remix-saas   \n",
       "6          codecrafters-io / build-your-own-x   \n",
       "7                          abi / secret-llama   \n",
       "8               Stirling-Tools / Stirling-PDF   \n",
       "9                               xM4ddy / OFGB   \n",
       "10                  fastfetch-cli / fastfetch   \n",
       "11                       KindXiaoming / pykan   \n",
       "12                           karpathy / llm.c   \n",
       "13              bepass-org / oblivion-desktop   \n",
       "14                          Ryujinx / Ryujinx   \n",
       "15             systemdesign42 / system-design   \n",
       "16                            lencx / ChatGPT   \n",
       "17                          lmstudio-ai / lms   \n",
       "18                           dockur / windows   \n",
       "19                              novuhq / novu   \n",
       "20                       solana-labs / solana   \n",
       "21                VinciGit00 / Scrapegraph-ai   \n",
       "22                       plandex-ai / plandex   \n",
       "23                 pagefaultgames / pokerogue   \n",
       "\n",
       "                               Repository_description Contributers  \n",
       "0   OpenUI let's you describe UI using your imagin...            8  \n",
       "1   A Windows and Office activator using HWID / Oh...            5  \n",
       "2                                 Create Magic Story!            5  \n",
       "3   Private & offline AI personal knowledge manage...           11  \n",
       "4   Implementing a ChatGPT-like LLM from scratch, ...          N/A  \n",
       "5   A Lightweight, Production-Ready Remix Stack fo...            6  \n",
       "6   Master programming by recreating your favorite...          116  \n",
       "7   Fully private LLM chatbot that runs entirely w...          N/A  \n",
       "8   #1 Locally hosted web application that allows ...            1  \n",
       "9   GUI Tool To Removes Ads From Various Places Ar...          N/A  \n",
       "10  Like neofetch, but much faster because written...           85  \n",
       "11                         Kolmogorov Arnold Networks            8  \n",
       "12                 LLM training in simple, raw C/CUDA          N/A  \n",
       "13             unofficial desktop version of oblivion            5  \n",
       "14  Experimental Nintendo Switch Emulator written ...          205  \n",
       "15        A resource to help you learn system design.          N/A  \n",
       "16  🔮 ChatGPT Desktop Application (Mac, Windows an...           30  \n",
       "17                         LM Studio in your terminal            2  \n",
       "18                     Windows in a Docker container.            7  \n",
       "19  🔥 The open-source notification infrastructure ...          398  \n",
       "20  Web-Scale Blockchain for fast, secure, scalabl...          491  \n",
       "21                         Python scraper based on AI          N/A  \n",
       "22  An AI coding engine for building complex, real...           13  \n",
       "23                                                  _           89  "
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96eb65b",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the  following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "753bfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "e1a75696",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "0b0cb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "871b1e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "1866f267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Billboard – Music Charts, News, Photos & Video\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "billboard_url = 'https://www.billboard.com/'\n",
    "driver.get(billboard_url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "9a47ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'NEW', 'Fortnight', 'Taylor Swift Featuring Post Malone', '-', '1', '1']\n",
      "['2', 'NEW', 'Down Bad', 'Taylor Swift', '-', '2', '1']\n",
      "['3', 'NEW', 'I Can Do It With A Broken Heart', 'Taylor Swift', '-', '3', '1']\n",
      "['4', 'NEW', 'The Tortured Poets Department', 'Taylor Swift', '-', '4', '1']\n",
      "['5', 'NEW', 'So Long, London', 'Taylor Swift', '-', '5', '1']\n",
      "['6', 'NEW', 'My Boy Only Breaks His Favorite Toys', 'Taylor Swift', '-', '6', '1']\n",
      "['7', 'NEW', 'But Daddy I Love Him', 'Taylor Swift', '-', '7', '1']\n",
      "['8', 'NEW', 'Florida!!!', 'Taylor Swift Featuring Florence + The Machine', '-', '8', '1']\n",
      "['9', 'NEW', \"Who's Afraid Of Little Old Me?\", 'Taylor Swift', '-', '9', '1']\n",
      "['10', 'NEW', 'Guilty As Sin?', 'Taylor Swift', '-', '10', '1']\n",
      "['']\n",
      "['11', 'NEW', 'Fresh Out The Slammer', 'Taylor Swift', '-', '11', '1']\n",
      "['12', 'NEW', 'loml', 'Taylor Swift', '-', '12', '1']\n",
      "['13', 'NEW', 'The Alchemy', 'Taylor Swift', '-', '13', '1']\n",
      "['14', 'NEW', 'The Smallest Man Who Ever Lived', 'Taylor Swift', '-', '14', '1']\n",
      "['15', 'Beautiful Things', 'Benson Boone', '3', '2', '14']\n",
      "['16', 'Too Sweet', 'Hozier', '1', '1', '5']\n",
      "['17', 'Like That', 'Future, Metro Boomin & Kendrick Lamar', '2', '1', '5']\n",
      "['18', 'Lose Control', 'Teddy Swims', '4', '1', '37']\n",
      "['19', 'NEW', 'Push Ups', 'Drake', '-', '19', '1']\n",
      "['20', 'NEW', 'I Can Fix Him (No Really I Can)', 'Taylor Swift', '-', '20', '1']\n",
      "['']\n",
      "['21', 'NEW', 'Clara Bow', 'Taylor Swift', '-', '21', '1']\n",
      "['22', 'Espresso', 'Sabrina Carpenter', '7', '7', '2']\n",
      "['23', 'NEW', 'thanK you aIMee', 'Taylor Swift', '-', '23', '1']\n",
      "['24', 'NEW', 'So High School', 'Taylor Swift', '-', '24', '1']\n",
      "['25', 'NEW', 'The Black Dog', 'Taylor Swift', '-', '25', '1']\n",
      "['26', 'NEW', 'imgonnagetyouback', 'Taylor Swift', '-', '26', '1']\n",
      "['27', 'A Bar Song (Tipsy)', 'Shaboozey', '36', '27', '2']\n",
      "['28', 'Lovin On Me', 'Jack Harlow', '6', '1', '24']\n",
      "['29', 'Saturn', 'SZA', '10', '6', '9']\n",
      "['30', 'NEW', 'The Albatross', 'Taylor Swift', '-', '30', '1']\n",
      "['']\n",
      "['31', \"Texas Hold 'Em\", 'Beyonce', '5', '1', '11']\n",
      "['32', 'NEW', 'The Prophecy', 'Taylor Swift', '-', '32', '1']\n",
      "['33', \"We Can't Be Friends (Wait For Your Love)\", 'Ariana Grande', '8', '1', '7']\n",
      "['34', 'NEW', 'I Hate It Here', 'Taylor Swift', '-', '34', '1']\n",
      "['35', 'NEW', 'How Did It End?', 'Taylor Swift', '-', '35', '1']\n",
      "['36', 'NEW', 'Chloe Or Sam Or Sophia Or Marcus', 'Taylor Swift', '-', '36', '1']\n",
      "['37', 'Stick Season', 'Noah Kahan', '9', '9', '30']\n",
      "['38', 'I Like The Way You Kiss Me', 'Artemas', '12', '12', '5']\n",
      "['39', 'NEW', \"I Look In People's Windows\", 'Taylor Swift', '-', '39', '1']\n",
      "['40', 'I Remember Everything', 'Zach Bryan Featuring Kacey Musgraves', '11', '1', '35']\n",
      "['']\n",
      "['41', 'Cruel Summer', 'Taylor Swift', '13', '1', '51']\n",
      "['42', 'Greedy', 'Tate McRae', '16', '3', '32']\n",
      "['43', 'Type Shit', 'Future, Metro Boomin, Travis Scott & Playboi Carti', '14', '2', '5']\n",
      "['44', 'NEW', 'Cassandra', 'Taylor Swift', '-', '44', '1']\n",
      "['45', 'Agora Hills', 'Doja Cat', '15', '7', '31']\n",
      "['46', 'NEW', 'Peter', 'Taylor Swift', '-', '46', '1']\n",
      "['47', 'NEW', 'The Bolter', 'Taylor Swift', '-', '47', '1']\n",
      "['48', 'Wanna Be', 'GloRilla & Megan Thee Stallion', '17', '11', '3']\n",
      "['49', 'Get It Sexyy', 'Sexyy Red', '23', '20', '6']\n",
      "['50', 'Feather', 'Sabrina Carpenter', '21', '21', '21']\n",
      "['']\n",
      "['51', 'NEW', 'The Manuscript', 'Taylor Swift', '-', '51', '1']\n",
      "['52', 'Carnival', '¥$: Ye & Ty Dolla $ign Featuring Rich The Kid & Playboi Carti', '20', '1', '11']\n",
      "['53', 'FTCU', 'Nicki Minaj', '80', '15', '20']\n",
      "['54', 'Whatever She Wants', 'Bryson Tiller', '31', '19', '10']\n",
      "['55', 'NEW', 'Robin', 'Taylor Swift', '-', '55', '1']\n",
      "['56', 'End Of Beginning', 'Djo', '24', '11', '10']\n",
      "['57', 'Redrum', '21 Savage', '25', '5', '15']\n",
      "['58', 'Gata Only', 'FloyyMenor X Cris Mj', '27', '27', '6']\n",
      "['59', 'Yeah Glo!', 'GloRilla', '32', '32', '11']\n",
      "['60', 'Austin', 'Dasha', '28', '28', '7']\n",
      "['']\n",
      "['61', 'Never Lose Me', 'Flo Milli', '33', '15', '19']\n",
      "['62', 'Good Luck, Babe!', 'Chappell Roan', '44', '44', '3']\n",
      "['63', 'Act II: Date @ 8', '4Batz Featuring Drake', '30', '7', '16']\n",
      "['64', 'Made For Me', 'Muni Long', '35', '20', '15']\n",
      "['65', 'Where It Ends', 'Bailey Zimmerman', '38', '32', '17']\n",
      "['66', 'Tell Ur Girlfriend', 'Lay Bankz', '58', '58', '2']\n",
      "['67', 'FE!N', 'Travis Scott Featuring Playboi Carti', '45', '5', '25']\n",
      "['68', 'Wild Ones', 'Jessie Murph & Jelly Roll', '46', '35', '29']\n",
      "['69', 'Slow It Down', 'Benson Boone', '49', '40', '5']\n",
      "['70', 'Cinderella', 'Future, Metro Boomin & Travis Scott', '37', '6', '5']\n",
      "['']\n",
      "['71', 'Wildflowers And Wild Horses', 'Lainey Wilson', '50', '48', '13']\n",
      "['72', 'Hell N Back', 'Bakar Featuring Summer Walker', '53', '53', '3']\n",
      "['73', 'Back Then Right Now', 'Tyler Hubbard', '62', '62', '6']\n",
      "['74', 'Obsessed', 'Olivia Rodrigo', '42', '14', '5']\n",
      "['75', 'Get In With Me', 'BossMan DLow', '52', '49', '12']\n",
      "['76', \"Wind Up Missin' You\", 'Tucker Wetmore', '75', '75', '4']\n",
      "['77', 'Mmhmm', 'BigXthaPlug', '63', '63', '18']\n",
      "['78', 'Illusion', 'Dua Lipa', '43', '43', '2']\n",
      "['79', 'Bulletproof', 'Nate Smith', '64', '64', '3']\n",
      "['80', 'Enough (Miami)', 'Cardi B', '55', '9', '6']\n",
      "['']\n",
      "['81', 'Everybody', 'Nicki Minaj Featuring Lil Uzi Vert', '65', '24', '20']\n",
      "['82', 'Scared To Start', 'Michael Marcagi', '56', '54', '10']\n",
      "['83', 'La Diabla', 'Xavi', '57', '20', '19']\n",
      "['84', 'II Most Wanted', 'Beyonce & Miley Cyrus', '47', '6', '4']\n",
      "['85', 'Cry', 'Benson Boone', '69', '60', '3']\n",
      "['86', 'Outskirts', 'Sam Hunt', '66', '66', '7']\n",
      "['87', 'Tu Name', 'Fuerza Regida', '68', '66', '10']\n",
      "['88', \"We Still Don't Trust You\", 'Future, Metro Boomin & The Weeknd', '22', '22', '2']\n",
      "['89', 'One Of The Girls', 'The Weeknd, Jennie & Lily Rose Depp', '70', '51', '18']\n",
      "['90', \"Let's Go\", 'Key Glock & Young Dolph', '59', '59', '7']\n",
      "['']\n",
      "['91', '23', 'Chayce Beckham', '74', '45', '17']\n",
      "['92', 'Tucson Too Late', 'Jordan Davis', '83', '80', '8']\n",
      "['93', 'Halfway To Hell', 'Jelly Roll', '85', '84', '3']\n",
      "['94', 'Praise Jah In The Moonlight', 'YG Marley', '76', '34', '13']\n",
      "['95', 'Feel It', 'd4vd', '94', '94', '2']\n",
      "['96', 'NEW', 'Us Vs. Them', '$uicideBoy$', '-', '96', '1']\n",
      "['97', 'Wine Into Whiskey', 'Tucker Wetmore', '84', '77', '5']\n",
      "['98', 'Spin You Around (1/24)', 'Morgan Wallen', '89', '24', '13']\n",
      "['99', 'Soak City', '310babii', '82', '53', '19']\n"
     ]
    }
   ],
   "source": [
    "#//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[1]\n",
    "\n",
    "select_billboard_tab = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[1]/a')))\n",
    "select_billboard_tab.click()\n",
    "#Scrap  data : A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board \n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[{i}]/ul/li[4]/ul  --> required fields \n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul\n",
    "\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[{i}] required files 1-6\n",
    "\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[i = 2 ] --main colum\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[11]\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[13]\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[13]\n",
    "#//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[24]\n",
    "Song_names = []\n",
    "Artist_name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "OnBoard_weeks = []\n",
    "\n",
    "for i in range(2,110):\n",
    "    try:\n",
    "        table_colum = WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[('+ str(i) +')]')))\n",
    "        table_data = table_colum.text.strip('\\n').split('\\n')\n",
    "        print(table_data)\n",
    "        Song_names.append(table_data[2])\n",
    "        Artist_name.append(table_data[3])\n",
    "        Last_week_rank.append(table_data[4])\n",
    "        Peak_rank.append(table_data[5])\n",
    "        OnBoard_weeks.append(table_data[6])\n",
    "    except IndexError:\n",
    "        continue \n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "0279f845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99, 99, 99, 33)"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Song_names),len(Artist_name),len(Last_week_rank),len(Peak_rank),len(OnBoard_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "67296554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_names</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fortnight</td>\n",
       "      <td>Taylor Swift Featuring Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down Bad</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Long, London</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>d4vd</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Us Vs. Them</td>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>310babii</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song_names                         Artist_name  \\\n",
       "0                         Fortnight  Taylor Swift Featuring Post Malone   \n",
       "1                          Down Bad                        Taylor Swift   \n",
       "2   I Can Do It With A Broken Heart                        Taylor Swift   \n",
       "3     The Tortured Poets Department                        Taylor Swift   \n",
       "4                   So Long, London                        Taylor Swift   \n",
       "..                              ...                                 ...   \n",
       "94                             d4vd                                  94   \n",
       "95                      Us Vs. Them                         $uicideBoy$   \n",
       "96                   Tucker Wetmore                                  84   \n",
       "97                    Morgan Wallen                                  89   \n",
       "98                         310babii                                  82   \n",
       "\n",
       "   Last_week_rank Peak_rank  \n",
       "0               -         1  \n",
       "1               -         2  \n",
       "2               -         3  \n",
       "3               -         4  \n",
       "4               -         5  \n",
       "..            ...       ...  \n",
       "94             94         2  \n",
       "95              -        96  \n",
       "96             77         5  \n",
       "97             24        13  \n",
       "98             53        19  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#,'OnBoard_weeks':OnBoard_weeks\n",
    "billboard_df = pd.DataFrame({'Song_names':Song_names,'Artist_name':Artist_name,'Last_week_rank':Last_week_rank,'Peak_rank':Peak_rank})\n",
    "billboard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ee3c8",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels. \n",
    "# A) Book name ,B) Author name ,C) Volumes sold ,D) Publisher ,E) Genre \n",
    "#Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "e0a7eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "fc303163",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "e459babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "3c85b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "9f1593fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Page Not Found | The Guardian\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "Novels_url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compar'\n",
    "driver.get(Novels_url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "74cdff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Book name ,B) Author name ,C) Volumes sold ,D) Publisher ,E) Genre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84bee0",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "#Url = https://www.imdb.com/list/ls512407256/ You have to find the following details: \n",
    "#A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1efb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1385aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6da24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6704138",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "587a571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Top 100 most watched tv shows of all time - IMDb\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "imdb_url = 'https://www.imdb.com/list/ls512407256/'\n",
    "driver.get(imdb_url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "615ca011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "Names = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "712ffd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Game of Thrones', 'Stranger Things', 'The Walking Dead', '13 Reasons Why', 'The 100', 'Orange Is the New Black', 'Riverdale', \"Grey's Anatomy\", 'The Flash', 'Arrow', 'Money Heist', 'The Big Bang Theory', 'Black Mirror', 'Sherlock', 'Vikings', 'Pretty Little Liars', 'The Vampire Diaries', 'American Horror Story', 'Breaking Bad', 'Lucifer', 'Supernatural', 'Prison Break', 'How to Get Away with Murder', 'Teen Wolf', 'The Simpsons', 'Once Upon a Time', 'Narcos', 'Daredevil', 'Friends', 'How I Met Your Mother', 'Suits', 'Mr. Robot', 'The Originals', 'Supergirl', 'Gossip Girl', 'Sense8', 'Gotham', 'Westworld', 'Jessica Jones', 'Modern Family', 'Rick and Morty', 'Shadowhunters', 'The End of the F***ing World', 'House of Cards', 'Dark', 'Elite', 'Sex Education', 'Shameless', 'New Girl', 'Agents of S.H.I.E.L.D.', 'Game of Thrones', 'You', 'Stranger Things', 'Dexter', 'The Walking Dead', 'Fear the Walking Dead', '13 Reasons Why', 'Family Guy', 'The 100', 'The Blacklist', 'Orange Is the New Black', 'Lost', 'Riverdale', 'Peaky Blinders', \"Grey's Anatomy\", 'House', 'The Flash', 'Quantico', 'Arrow', 'Orphan Black', 'Money Heist', 'Homeland', 'The Big Bang Theory', 'Blindspot', 'Black Mirror', \"DC's Legends of Tomorrow\", 'Sherlock', \"The Handmaid's Tale\", 'Vikings', 'Chilling Adventures of Sabrina', 'Pretty Little Liars', 'The Good Doctor', 'The Vampire Diaries', 'Jane the Virgin', 'American Horror Story', 'Glee', 'Breaking Bad', 'South Park', 'Lucifer', 'Brooklyn Nine-Nine', 'Supernatural', 'Under the Dome', 'Prison Break', 'The Umbrella Academy', 'How to Get Away with Murder', 'True Detective', 'Teen Wolf', 'The OA', 'The Simpsons', 'Desperate Housewives']\n"
     ]
    }
   ],
   "source": [
    "#https://www.imdb.com/list/ls512407256/  for Q 7\n",
    "                                                   \n",
    "#names = soup.find_all('div',class_=\"ipc-title__text\")\n",
    "name_element = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in name_element:\n",
    "        nam = i.text\n",
    "        Names.append(nam)\n",
    "\n",
    "print(Names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82e75195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2011–2019', '2016–2025', '2010–2022', '2017–2020', '2014–2020', '2013–2019', '2017–2023', '2005– ', '2014–2023', '2012–2020', '2017–2021', '2007–2019', '2011– ', '2010–2017', '2013–2020', '2010–2017', '2009–2017', '2011– ', '2008–2013', '2016–2021', '2005–2020', '2005–2017', '2014–2020', '2011–2017', '1989– ', '2011–2018', '2015–2017', '2015–2018', '1994–2004', '2005–2014', '2011–2019', '2015–2019', '2013–2018', '2015–2021', '2007–2012', '2015–2018', '2014–2019', '2016–2022', '2015–2019', '2009–2020', '2013– ', '2016–2019', '2017–2019', '2013–2018', '2017–2020', '2018–2024', '2019–2023', '2011–2021', '2011–2018', '2013–2020', '2011–2019', '2018–2024', '2016–2025', '2006–2013', '2010–2022', '2015–2023', '2017–2020', '1999– ', '2014–2020', '2013–2023', '2013–2019', '2004–2010', '2017–2023', '2013–2022', '2005– ', '2004–2012', '2014–2023', '2015–2018', '2012–2020', '2013–2017', '2017–2021', '2011–2020', '2007–2019', '2015–2020', '2011– ', '2016–2022', '2010–2017', '2017– ', '2013–2020', '2018–2020', '2010–2017', '2017–2024', '2009–2017', '2014–2019', '2011– ', '2009–2015', '2008–2013', '1997– ', '2016–2021', '2013–2021', '2005–2020', '2013–2015', '2005–2017', '2019–2024', '2014–2020', '2014– ', '2011–2017', '2016–2019', '1989– ', '2004–2012']\n"
     ]
    }
   ],
   "source": [
    "Year_spans = []\n",
    "\n",
    "Year_sps= driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in Year_sps:\n",
    "    Year_sp = i.text.strip(\"(,)\")\n",
    "    Year_spans.append(Year_sp)\n",
    "\n",
    "print(Year_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a5894d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Horror, Thriller', 'Drama, Mystery, Thriller', 'Drama, Mystery, Sci-Fi', 'Comedy, Crime, Drama', 'Crime, Drama, Mystery', 'Drama, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Crime', 'Action, Crime, Drama', 'Comedy, Romance', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Action, Adventure, Drama', 'Drama, Mystery, Romance', 'Drama, Fantasy, Horror', 'Drama, Horror, Sci-Fi', 'Crime, Drama, Thriller', 'Crime, Drama, Fantasy', 'Drama, Fantasy, Horror', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Animation, Comedy', 'Adventure, Fantasy, Romance', 'Biography, Crime, Drama', 'Action, Crime, Drama', 'Comedy, Romance', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Crime, Drama, Thriller', 'Drama, Fantasy, Horror', 'Action, Adventure, Drama', 'Drama, Romance', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Comedy, Drama, Romance', 'Animation, Adventure, Comedy', 'Action, Drama, Fantasy', 'Adventure, Comedy, Crime', 'Drama', 'Crime, Drama, Mystery', 'Crime, Drama, Thriller', 'Comedy, Drama, Romance', 'Comedy, Drama', 'Comedy, Romance', 'Action, Adventure, Drama', 'Action, Adventure, Drama', 'Crime, Drama, Romance', 'Drama, Fantasy, Horror', 'Crime, Drama, Mystery', 'Drama, Horror, Thriller', 'Drama, Horror, Sci-Fi', 'Drama, Mystery, Thriller', 'Animation, Comedy', 'Drama, Mystery, Sci-Fi', 'Crime, Drama, Mystery', 'Comedy, Crime, Drama', 'Adventure, Drama, Fantasy', 'Crime, Drama, Mystery', 'Crime, Drama', 'Drama, Romance', 'Drama, Mystery', 'Action, Adventure, Drama', 'Crime, Drama, Mystery', 'Action, Adventure, Crime', 'Drama, Sci-Fi, Thriller', 'Action, Crime, Drama', 'Crime, Drama, Mystery', 'Comedy, Romance', 'Action, Crime, Drama', 'Drama, Mystery, Sci-Fi', 'Action, Adventure, Drama', 'Crime, Drama, Mystery', 'Drama, Sci-Fi, Thriller', 'Action, Adventure, Drama', 'Drama, Fantasy, Horror', 'Drama, Mystery, Romance', 'Drama', 'Drama, Fantasy, Horror', 'Comedy', 'Drama, Horror, Sci-Fi', 'Comedy, Drama, Music', 'Crime, Drama, Thriller', 'Animation, Comedy', 'Crime, Drama, Fantasy', 'Comedy, Crime', 'Drama, Fantasy, Horror', 'Drama, Mystery, Sci-Fi', 'Action, Crime, Drama', 'Action, Adventure, Comedy', 'Crime, Drama, Mystery', 'Crime, Drama, Mystery', 'Action, Drama, Fantasy', 'Drama, Fantasy, Mystery', 'Animation, Comedy', 'Comedy, Drama, Mystery']\n"
     ]
    }
   ],
   "source": [
    "Genre_s = []\n",
    "\n",
    "Genres = driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "for i in Genres:\n",
    "    Genre = i.text\n",
    "    Genre_s.append(Genre)\n",
    "\n",
    "print(Genre_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa2117d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9.2', '8.7', '8.1', '7.5', '7.6', '8', '6.5', '7.6', '7.5', '7.5', '8.2', '8.1', '8.7', '9.1', '8.5', '7.4', '7.7', '8', '9.5', '8.1', '8.4', '8.3', '8.1', '7.7', '8.7', '7.7', '8.8', '8.6', '8.9', '8.3', '8.4', '8.5', '8.3', '6.2', '7.5', '8.2', '7.8', '8.5', '7.9', '8.5', '9.1', '6.5', '8', '8.6', '8.7', '7.2', '8.3', '8.5', '7.8', '7.5', '9.2', '7.7', '8.7', '8.6', '8.1', '6.8', '7.5', '8.1', '7.6', '7.9', '8', '8.3', '6.5', '8.8', '7.6', '8.7', '7.5', '6.7', '7.5', '8.3', '8.2', '8.3', '8.1', '7.3', '8.7', '6.8', '9.1', '8.4', '8.5', '7.4', '7.4', '8', '7.7', '7.9', '8', '6.8', '9.5', '8.7', '8.1', '8.4', '8.4', '6.5', '8.3', '7.9', '8.1', '8.9', '7.7', '7.8', '8.7', '7.6']\n"
     ]
    }
   ],
   "source": [
    "Ratings = []\n",
    "Votes = []\n",
    "rate_s = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for i in rate_s:\n",
    "    rate = i.text\n",
    "    Ratings.append(rate)\n",
    "\n",
    "print(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a65fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,287,886', '1,338,701', '1,083,526', '315,825', '276,596', '320,381', '155,300', '342,298', '368,413', '446,219', '532,918', '869,133', '640,972', '1,000,227', '583,822', '178,488', '350,196', '344,388', '2,140,480', '356,420', '483,712', '580,012', '166,858', '163,419', '436,360', '237,202', '470,908', '475,160', '1,089,398', '729,087', '479,752', '418,679', '148,013', '129,644', '193,626', '163,147', '240,868', '533,406', '226,906', '484,392', '602,520', '70,646', '220,437', '531,246', '445,153', '90,888', '351,968', '286,043', '245,746', '226,080', '2,287,886', '300,322', '1,338,701', '767,940', '1,083,526', '144,690', '315,825', '364,632', '276,596', '279,879', '320,381', '595,918', '155,300', '651,110', '342,298', '514,568', '368,413', '63,918', '446,219', '117,039', '532,918', '361,131', '869,133', '79,100', '640,972', '110,097', '1,000,227', '258,283', '583,822', '108,667', '178,488', '113,367', '350,196', '59,138', '344,388', '155,536', '2,140,480', '406,279', '356,420', '364,153', '483,712', '112,618', '580,012', '275,750', '166,858', '657,440', '163,419', '116,002', '436,360', '139,920']\n"
     ]
    }
   ],
   "source": [
    "Votes = []\n",
    "vote_s = driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for i in vote_s:\n",
    "    vote = i.text\n",
    "    Votes.append(vote)\n",
    "\n",
    "print(Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4793e037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Votes),len(Ratings),len(Genre_s),len(Year_spans),len(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2b2891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_imdb = pd.DataFrame({'Names':Names,'Year_spans':Year_spans,'Genre':Genre_s,'Ratings':Ratings,'Votes':Votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca6a6af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Year_spans</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,287,886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–2025</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,338,701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,083,526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>315,825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>276,596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>2014–</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.9</td>\n",
       "      <td>657,440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>2011–2017</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>2016–2019</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>7.8</td>\n",
       "      <td>116,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>1989–</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>2004–2012</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139,920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Names Year_spans                     Genre Ratings  \\\n",
       "0        Game of Thrones  2011–2019  Action, Adventure, Drama     9.2   \n",
       "1        Stranger Things  2016–2025    Drama, Fantasy, Horror     8.7   \n",
       "2       The Walking Dead  2010–2022   Drama, Horror, Thriller     8.1   \n",
       "3         13 Reasons Why  2017–2020  Drama, Mystery, Thriller     7.5   \n",
       "4                The 100  2014–2020    Drama, Mystery, Sci-Fi     7.6   \n",
       "..                   ...        ...                       ...     ...   \n",
       "95        True Detective     2014–      Crime, Drama, Mystery     8.9   \n",
       "96             Teen Wolf  2011–2017    Action, Drama, Fantasy     7.7   \n",
       "97                The OA  2016–2019   Drama, Fantasy, Mystery     7.8   \n",
       "98          The Simpsons     1989–          Animation, Comedy     8.7   \n",
       "99  Desperate Housewives  2004–2012    Comedy, Drama, Mystery     7.6   \n",
       "\n",
       "        Votes  \n",
       "0   2,287,886  \n",
       "1   1,338,701  \n",
       "2   1,083,526  \n",
       "3     315,825  \n",
       "4     276,596  \n",
       "..        ...  \n",
       "95    657,440  \n",
       "96    163,419  \n",
       "97    116,002  \n",
       "98    436,360  \n",
       "99    139,920  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a3386",
   "metadata": {},
   "source": [
    "# Q8.  Details of Datasets from UCI machine learning repositories. \n",
    "#Url = https://archive.ics.uci.edu/ You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year \n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80df33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import time\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36aed6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = 'C:/Users/nallag/source/Student/DATAScience_DOC/studocu_doc/chromedriver_win32/chromedriver.exe'\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4217014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: UCI Machine Learning Repository\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "archive_url = 'https://archive.ics.uci.edu/'\n",
    "driver.get(archive_url)\n",
    "print(\"Page Title:\",driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065a21d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
