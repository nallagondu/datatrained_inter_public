{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPKwj/5FfXKVdVwNwtgVf+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/datatrained_inter_public/blob/main/Insurance_Claim_Fraud_Detection_3phase_Evaluation3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV2NQ34Yfich"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Project Description**\n",
        "\n",
        "Insurance fraud is a huge problem in the industry. It's difficult to identify fraud claims. Machine Learning is in a unique position to help the Auto Insurance industry with this problem.\n",
        "\n",
        "In this project, you are provided a dataset which has the details of the insurance policy along with the customer details. It also has the details of the accident on the basis of which the claims have been made.\n",
        "In this example, you will be working with some auto insurance data to demonstrate how you can create a predictive model that predicts if an insurance claim is fraudulent or not.\n",
        "\n",
        "\n",
        "**Independent Variables**\n",
        "\n",
        "1.\tmonths_as_customer: Number of months of patronage\n",
        "\n",
        "2.\tage: the length of time a customer has lived or a thing has existed\n",
        "\n",
        "3.\tpolicy_number: It is a unique id given to the customer, to track the subscription status and other details of customer\n",
        "\n",
        "4.\tpolicy_bind_date:date which document that is given to customer after we accept your proposal for insurance\n",
        "\n",
        "5.\tpolicy_state: This identifies who is the insured, what risks or property are covered, the policy limits, and the policy period\n",
        "\n",
        "6.\tpolicy_csl: is basically Combined Single Limit\n",
        "\n",
        "7.\tpolicy_deductable: the amount of money that a customer is responsible for paying toward an insured loss\n",
        "\n",
        "8.\tpolicy_annual_premium: This means the amount of Regular Premium payable by the Policyholder in a Policy Year\n",
        "\n",
        "9.\tumbrella_limit: This means extra insurance that provides protection beyond existing limits and coverages of other policies\n",
        "\n",
        "10.\tinsured_zip: It is the zip code where the insurance was made\n",
        "\n",
        "11.\tinsured_sex: This refres to either of the two main categories (male and female) into which customer are divided on the basis of their reproductive functions\n",
        "\n",
        "12.\tinsured_education_level: This refers to the Level of education of the customer\n",
        "\n",
        "13.\tinsured_occupation: This refers Occupation of the customer\n",
        "\n",
        "14.\tinsured_hobbies: This refers to an activity done regularly by customer in his/her leisure time for pleasure.\n",
        "\n",
        "15.\tinsured_relationship: This whether customer is: single; or. married; or. in a de facto relationship (that is, living together but not married); or. in a civil partnership\n",
        "\n",
        "16.\tcapital-gains: This refers to profit accrued due to insurance premium\n",
        "\n",
        "17.\tcapital-loss: This refers to the losses incurred due to insurance claims\n",
        "\n",
        "18.\tincident_date: This refers to the date which claims where made by customers\n",
        "\n",
        "19.\tincident_type: This refers to the type of claim/vehicle damage made by customer\n",
        "\n",
        "20.\tcollision_type: This refers to the area of damage on the vehicle\n",
        "\n",
        "21.\tincident_severity: This refers to the extent/level of damage\n",
        "\n",
        "22.\tauthorities_contacted: This refers to the government agencies that were contacted after damage\n",
        "\n",
        "23.\tincident_state: This refers to the state at which the accident happened\n",
        "\n",
        "24.\tincident_city: This refers to the city at which the accident happened\n",
        "\n",
        "25.\t1ncident_location: This refers to the location at which the accident happened\n",
        "\n",
        "26.\tincident_hour_of_the_day: The period of the day which accident took place\n",
        "\n",
        "27.\tnumber_of_vehicles_involved: This refers to number of vehicles involved the accident\n",
        "\n",
        "28.\tproperty_damage: This refers to whether property was damaged or not\n",
        "\n",
        "29.\tbodily_injuries: This refers to injuries sustained\n",
        "\n",
        "30.\twitnesses: This refers to the number of witnesses involved\n",
        "\n",
        "31.\tpolice_report_available: This refers to whether the report on damage was documented or not\n",
        "\n",
        "32.\ttotal_claim_amount: This refers to the financial implications involved in claims\n",
        "\n",
        "33.\tinjury_claim: This refers to physical injuries sustained\n",
        "\n",
        "34.\tproperty_claim: This refers to property damages during incident\n",
        "\n",
        "35.\tvehicle_claim: This refers to property damages during incident\n",
        "\n",
        "36.\tauto_make: This refers to the make of the vehicle\n",
        "\n",
        "37.\tauto_model: This refers to the model of the vehicle\n",
        "\n",
        "38.\tauto_year: This refers to the year which the vehicle was manufactured\n",
        "\n",
        "39.\tfraud_reported\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w4tko2qogENs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Dataset Link-**\n",
        "\n",
        "\n",
        "â€¢\thttps://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Insurance%20Claim%20Fraud%20Detection/Automobile_insurance_fraud.csv\n"
      ],
      "metadata": {
        "id": "a5IP9u0RiSL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Step ,we are going to start with **Data Preparation**\n",
        "\n",
        "- To load the dataset using above URl\n",
        "- To handel missing values\n",
        "- To encode categoricl variavles\n",
        "- To Siplit the dataset into training and testing sets"
      ],
      "metadata": {
        "id": "zyFZXW-tiv7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To load the dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Insurance%20Claim%20Fraud%20Detection/Automobile_insurance_fraud.csv'\n",
        "df_ICFD = pd.read_csv(dataset_url)\n",
        "df_ICFD.head()\n"
      ],
      "metadata": {
        "id": "J42EWuoeitbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In above data I didn't see headers part  and I need to add header column\n",
        "\n",
        "headers_col = [\n",
        "    'months_as_customer', 'age', 'policy_number', 'policy_bind_date', 'policy_state','policy_csl', 'policy_deductable', 'policy_annual_premium', 'umbrella_limit', 'insured_zip',\n",
        "    'insured_sex', 'insured_education_level', 'insured_occupation', 'insured_hobbies', 'insured_relationship','capital_gains', 'capital_loss', 'incident_date', 'incident_type', 'collision_type',\n",
        "    'incident_severity', 'authorities_contacted', 'incident_state', 'incident_city', 'incident_location','incident_hour_of_the_day', 'number_of_vehicles_involved', 'property_damage', 'bodily_injuries', 'witnesses',\n",
        "    'police_report_available', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim','auto_make', 'auto_model', 'auto_year', 'fraud_reported'\n",
        "]\n",
        "df_ICFD.columns = headers_col\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "Gnjhzte2pzrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.shape"
      ],
      "metadata": {
        "id": "DZTm_zg6qhuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.info()"
      ],
      "metadata": {
        "id": "y-QUQmUzwSjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find any missing values\n",
        "df_ICFD.isnull().sum()"
      ],
      "metadata": {
        "id": "DajSsNViw80E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD['authorities_contacted'].value_counts()"
      ],
      "metadata": {
        "id": "Fp7kjkSBxcYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD['authorities_contacted'].fillna(df_ICFD['authorities_contacted'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "jqmWPecsy9IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we used mode method to manage the missing values in  '**authorities_contacted**'"
      ],
      "metadata": {
        "id": "GDEL9yi6zepb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.duplicated().sum()"
      ],
      "metadata": {
        "id": "qBw_RkBGzqgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.nunique()"
      ],
      "metadata": {
        "id": "LtvVNLK3KNEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical Columns Unique values encoding\n",
        "\n",
        "df_ICFD['policy_state'].value_counts()\n",
        "\n"
      ],
      "metadata": {
        "id": "lS_uPKSMLWfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD['authorities_contacted'].value_counts()"
      ],
      "metadata": {
        "id": "T4PLLLUtzSGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find any missing values\n",
        "df_ICFD.isnull().sum()"
      ],
      "metadata": {
        "id": "MpBmEpwozYVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fD2SA0cH0HRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert date columns like 'policy_bind_date '  and 'incident_date'\n",
        "df_ICFD['policy_bind_date'] = pd.to_datetime(df_ICFD['policy_bind_date'], format ='%d-%m-%Y')\n",
        "df_ICFD['incident_date'] = pd.to_datetime(df_ICFD['incident_date'],format ='%d-%m-%Y')\n",
        "\n",
        "# Extract year and month ,day as new features\n",
        "\n",
        "df_ICFD['policy_bind_year'] = df_ICFD['policy_bind_date'].dt.year\n",
        "df_ICFD['policy_bind_month'] = df_ICFD['policy_bind_date'].dt.month\n",
        "df_ICFD['policy_bind_day'] = df_ICFD['policy_bind_date'].dt.day\n",
        "df_ICFD['incident_year'] = df_ICFD['incident_date'].dt.year\n",
        "df_ICFD['incident_month'] = df_ICFD['incident_date'].dt.month\n",
        "df_ICFD['incident_day'] = df_ICFD['incident_date'].dt.day\n",
        "\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "YRhHgbl4z8r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.info()"
      ],
      "metadata": {
        "id": "Qnh0YiJH1b6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop policy_bind_date and incident_date\n",
        "df_ICFD.drop(['policy_bind_date', 'incident_date'], axis=1, inplace=True)\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "PM9mydTC1k7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ICFD.columns ,'\\n')\n",
        "\n",
        "df_objectes_list =df_ICFD.dtypes[df_ICFD.dtypes == 'object']\n",
        "df_objectes_list"
      ],
      "metadata": {
        "id": "LIl4pTAdFAnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_objectes_list.index)):\n",
        "  print( df_ICFD[df_objectes_list.index[i]].value_counts(), '\\n')\n"
      ],
      "metadata": {
        "id": "9C3BgtMeFq7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#policy_state               category\n",
        "policy_csl                 category\n",
        "insured_sex                category\n",
        "insured_education_level    object\n",
        "insured_occupation         object\n",
        "insured_hobbies            object\n",
        "insured_relationship       object\n",
        "incident_type              object\n",
        "collision_type             object\n",
        "incident_severity          object\n",
        "authorities_contacted      object\n",
        "incident_state             object\n",
        "incident_city              object\n",
        "incident_location          object\n",
        "property_damage            category\n",
        "bodily_injuries            object\n",
        "witnesses                  object\n",
        "police_report_available    category\n",
        "auto_year                  object\n",
        "auto_make                  object\n",
        "auto_model                 object\n",
        "fraud_reported                category\"\"\"\n"
      ],
      "metadata": {
        "id": "IwS-WVamMq9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.preprocessing as preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "##Binary and Small numbers of categories\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "label_col = ['policy_state', 'policy_csl', 'insured_sex', 'property_damage', 'police_report_available', 'fraud_reported']\n",
        "for col in label_col:\n",
        "    df_ICFD[col] = le.fit_transform(df_ICFD[col])\n",
        "\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "iQ0680R6NXTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "num_df = df_ICFD.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "fige, ax = plt.subplots(figsize=(25, 20))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "sns.heatmap(num_df.corr(), annot=True,vmax = .3, cmap=cmap, ax=ax)\n",
        "\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5JLln05N-xia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here first correlation between Age and months_as_customers is have high correlation  : 0.92\n",
        "\n",
        "as well as  :          \n",
        "total_claim_amount vs  injury_clime (0.81)\n",
        "total_claim_amount vs property_clime (0.81)\n",
        "total_claim_amount vs Vehicle_clime(0.98)\n",
        "injury_clime vs Vehicle_clime (0.72)\n",
        "property_clime vs Vehicle_clime(0.73)\n",
        "  between this four have high positive  correlation .\n",
        "\n",
        "property_clime vs injury_clime (0.56)\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "p4EgvqVp_4Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical columns with many Unique values\n",
        "#policy_number, insured_zip , incident_location ,auto_make,auto_model\n",
        "\n",
        "#Unique values : 999,994,999,14,39\n",
        "\n",
        "def frequency_encoding(df_ICFD,column):\n",
        "  freq= df_ICFD[column].value_counts()\n",
        "  df_ICFD[column + '_freq']=df_ICFD[column].map(freq)\n",
        "  df_ICFD.drop(column,axis=1,inplace=True)\n",
        "\n",
        "frequency_col = ['policy_number','insured_zip', 'incident_location', 'auto_make', 'auto_model']\n",
        "for col in frequency_col:\n",
        "  frequency_encoding(df_ICFD,col)\n",
        "\n",
        "df_ICFD.head()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f8Gpk4XyNz3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot Encoding or label encoding\n",
        "one_hot_ecode_col  = ['insured_education_level','insured_occupation','insured_hobbies','insured_relationship','incident_type', 'collision_type', 'incident_severity', 'authorities_contacted', 'incident_state', 'incident_city']\n",
        "df_ICFD = pd.get_dummies(df_ICFD, columns=one_hot_ecode_col, drop_first=True)\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "EfKyvJtCQtn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.info()"
      ],
      "metadata": {
        "id": "LQcGDJhbSv7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.dtypes"
      ],
      "metadata": {
        "id": "3aMfZEFYK4Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.describe()"
      ],
      "metadata": {
        "id": "OYlM4chpUos4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "Y6zAZM35RrsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bool_val = df_ICFD.select_dtypes(include='bool').columns\n",
        "df_ICFD[bool_val] = df_ICFD[bool_val].astype(int)\n",
        "df_ICFD.head()"
      ],
      "metadata": {
        "id": "k3nAcCxsVmzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ICFD.isnull().sum())"
      ],
      "metadata": {
        "id": "8EOMLzu9VPxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD.describe()"
      ],
      "metadata": {
        "id": "frXUwPgkVUS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_cols = df_ICFD.select_dtypes(include=['object']).columns\n",
        "print(object_cols)"
      ],
      "metadata": {
        "id": "di4R-2-tWdaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ICFD['fraud_reported'].value_counts()\n"
      ],
      "metadata": {
        "id": "kuXis8fMpMFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Skewness\n",
        "skewness = df_ICFD.skew()\n",
        "skewness"
      ],
      "metadata": {
        "id": "XGau7kQcpohW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8Jri8yRD052"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGUEH4BdD44O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fige, ax = plt.subplots(figsize=(25, 20))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "sns.heatmap(df_ICFD.corr(), annot=True,vmax = .3, cmap=cmap, ax=ax)\n",
        "\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DyjlSCXy7Rq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "for feature in df_ICFD.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(df_ICFD[feature], kde=True)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MtI75T-RqZR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for Box plot\n",
        "\n",
        "for feature in df_ICFD.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=df_ICFD[feature])\n",
        "    plt.title(f'Box Plot of {feature}')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tdP-tJear_tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f,ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "sns.countplot(x='fraud_reported', data=df_ICFD)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dw6FacnDD6hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here I can find more hobbies in Insured ,I need to melt it in insured columns\n",
        "\n",
        "df_melted = pd.melt(df_ICFD, id_vars=['fraud_reported'], value_vars=[col for col in df_ICFD.columns if 'insured_hobbies_' in col ],var_name = 'insured_hobbies', value_name='is_hobbies')\n",
        "df_melted = df_melted[df_melted['is_hobbies'] == 1]\n",
        "df_melted.head()\n",
        "\n",
        "f,ax = plt.subplots(figsize=(10, 8))\n",
        "sns.countplot(x='fraud_reported', hue = 'insured_hobbies', data=df_melted)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bcH-R8sMFFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Second time correlation test\n",
        "\n",
        "corr = df_ICFD.corr()\n",
        "corr\n"
      ],
      "metadata": {
        "id": "y6RkgPQjh6bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm==3.3.2\n"
      ],
      "metadata": {
        "id": "_gXyBud_wYut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "X = df_ICFD.drop('fraud_reported', axis=1)\n",
        "y = df_ICFD['fraud_reported']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6E-_40k9ijFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "def lgb_f1_score(y_hat, df_ICFD):\n",
        "    y_true = df_ICFD.get_label()\n",
        "    y_hat = np.where(y_hat < 0.5, 0, 1)  # Convert probabilities to 0/1\n",
        "    return 'f1',  f1_score(y_true, y_hat),True"
      ],
      "metadata": {
        "id": "YHW8wHbqinRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r_lgb(X_train, X_test, y_train, y_test, test_data):\n",
        "  params = {\n",
        "      'objective': 'binary',\n",
        "      'metric': 'f1',\n",
        "      'boosting': 'gbdt',\n",
        "      'num_leaves': 3,\n",
        "      'learning_rate': 0.05,\n",
        "      'feature_fraction': 0.9,\n",
        "      #'bagging_fraction': 0.8,\n",
        "      'bagging_freq': 5,\n",
        "      'verbose': 0,\n",
        "      'num_iterations': 200,\n",
        "      'n_jobs': -1,\n",
        "      'random_state': 42,\n",
        "      'lambda_l1': 0.1,\n",
        "      'lambda_l2': 0.1,\n",
        "      'min_data_in_leaf': 10,\n",
        "      'max_depth': -1,\n",
        "      'min_child_weight': 0.001,\n",
        "      'reg_alpha': 0.5,\n",
        "      'reg_lambda': 0.5,\n",
        "      'min_split_gain': 0.0222415,\n",
        "      'subsample': 1.0,\n",
        "      'subsample_freq': 1,\n",
        "      'force_row_wise': True\n",
        "  }\n",
        "\n",
        "  X_train.columns = [col.replace(' ','_') for col in X_train.columns]\n",
        "  X_test.columns = [col.replace(' ','_') for col in X_test.columns]\n",
        "\n",
        "  # Create LightGBM datasets\n",
        "  lgtrain = lgb.Dataset(X_train, label=y_train)\n",
        "  lgval = lgb.Dataset(X_test, label=y_test)\n",
        "  evals_result = {}\n",
        "  model = lgb.train(params, lgtrain, 5000,\n",
        "                      valid_sets=[lgtrain, lgval],\n",
        "                      early_stopping_rounds=100,\n",
        "                      verbose_eval=100,\n",
        "                      evals_result=evals_result,feval = lgb_f1_score)\n",
        "  pred_test_y = model.predict(test_data,num_iteration = model.best_iteration)\n",
        "  return pred_test_y, model, evals_result"
      ],
      "metadata": {
        "id": "Pu-Mviq_lUvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "pred_test, model,evals_result = r_lgb(X_train, X_test, y_train, y_test, X_test)\n",
        "\n",
        "#Convert probabilities to 0/1 predictions\n",
        "pred_test_binary = np.where(pred_test < 0.5, 0, 1)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, pred_test_binary)\n",
        "\n",
        "# Print the F1 score\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"LightGBM Model Performance\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, pred_test_binary)}\")\n"
      ],
      "metadata": {
        "id": "lZhggY2csrPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test,pred_test)\n",
        "\n",
        "#roc_auc_score(y_test,pred_test_binary)"
      ],
      "metadata": {
        "id": "S_kb5kE7zUAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, pred_test)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Ps2A8gj5Nwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_test)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M1j1kqwT6Mhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('plot features')\n",
        "\n",
        "ax = lgb.plot_importance(model, max_num_features=20, height=0.5)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "c7vfq6cn7gyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import xgboost as xgb\n"
      ],
      "metadata": {
        "id": "LvkKbmbU-Oj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "          'svc':SVC(),\n",
        "          'rfc':RandomForestClassifier(),\n",
        "          'knc':KNeighborsClassifier(),\n",
        "          'gau':GaussianNB(),\n",
        "          'dtc' : DecisionTreeClassifier(),\n",
        "          'abc' : AdaBoostClassifier(),\n",
        "          'grd':GradientBoostingClassifier(),\n",
        "          'bagg':BaggingClassifier(),\n",
        "          'xgb':xgb.XGBClassifier(),\n",
        "          'lgb':lgb.LGBMClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "XObarCts-rke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#train AND evalate classifiers for primary fuel predection\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "  classifier.fit(X_train,y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  print(f'{name} : {accuracy}')"
      ],
      "metadata": {
        "id": "_0CXYF_G-ZTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GaussianNB_model = GaussianNB()\n",
        "GaussianNB_model.fit(X_train,y_train)\n",
        "y_pred = GaussianNB_model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy : {Accuracy}')"
      ],
      "metadata": {
        "id": "vKrVYe5S-5PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GaussianNB_model = GaussianNB()\n",
        "GaussianNB_model.fit(X_train,y_train)\n",
        "y_pred = GaussianNB_model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy : {Accuracy}')"
      ],
      "metadata": {
        "id": "WHRxWQAI_Ath"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_model = SVC()\n",
        "SVC_model.fit(X_train,y_train)\n",
        "y_pred = SVC_model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy SVC_model: {Accuracy}')"
      ],
      "metadata": {
        "id": "axBhHSjK_PlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ada_model = AdaBoostClassifier()\n",
        "Ada_model.fit(X_train,y_train)\n",
        "y_pred = Ada_model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy Ada_model: {Accuracy}')"
      ],
      "metadata": {
        "id": "iH_CgZlz_beO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gradient_model  = GradientBoostingClassifier()\n",
        "Gradient_model.fit(X_train,y_train)\n",
        "y_pred = Gradient_model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy Gradient_model: {Accuracy}')"
      ],
      "metadata": {
        "id": "u-cTuE6-_rh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Best model\n",
        "we can consider **GradientBoostingClassifier** is the best model when I compare with other models in above list"
      ],
      "metadata": {
        "id": "WRTpHP-VAHLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'Gradient_model.pkl'\n",
        "pickle.dump(Gradient_model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "IfI06eMs_7yL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}