{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPSGSs8iEyKrCRn7X9s5g39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/datatrained_inter_public/blob/main/HR_Analytics_Project_First_Phase_Evaluation_Projects_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HR Analytics Project-** Understanding the Attrition in HR\n",
        "Project Description\n",
        "Every year a lot of companies hire a number of employees. The companies invest time and money in training those employees, not just this but there are training programs within the companies for their existing employees as well. The aim of these programs is to increase the effectiveness of their employees. But where HR Analytics fit in this? and is it just about improving the performance of employees?\n",
        "\n",
        "**HR Analytics**\n",
        "Human resource analytics (HR analytics) is an area in the field of analytics that refers to applying analytic processes to the human resource department of an organization in the hope of improving employee performance and therefore getting a better return on investment. HR analytics does not just deal with gathering data on employee efficiency. Instead, it aims to provide insight into each process by gathering data and then using it to make relevant decisions about how to improve these processes.\n",
        "\n",
        "**Attrition in HR**\n",
        "Attrition in human resources refers to the gradual loss of employees overtime. In general, relatively high attrition is problematic for companies. HR professionals often assume a leadership role in designing company compensation programs, work culture, and motivation systems that help the organization retain top employees.\n",
        "\n",
        "**How does Attrition affect companies?**\n",
        "and how does HR Analytics help in analyzing attrition? We will discuss the first question here and for the second question, we will write the code and try to understand the process step by step.\n",
        "\n",
        "**Attrition affecting Companies**\n",
        "A major problem in high employee attrition is its cost to an organization. Job postings, hiring processes, paperwork, and new hire training are some of the common expenses of losing employees and replacing them. Additionally, regular employee turnover prohibits your organization from increasing its collective knowledge base and experience over time. This is especially concerning if your business is customer-facing, as customers often prefer to interact with familiar people. Errors and issues are more likely if you constantly have new workers.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "izM4BlOGH-Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Link-**\n",
        "â€¢\thttps://github.com/FlipRoboTechnologies/ML_-Datasets/blob/main/HR%20Analytics/ibm-hr-analytics-employee-attrition-performance.zip\n"
      ],
      "metadata": {
        "id": "rfThmv20IWnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.for Visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 2.for Warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 3. For data Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score # Import cross_val_score\n",
        "#from sklearn.feature_selection import\n",
        "\n",
        "#4. For predection the models\n",
        "\n",
        "from sklearn.linear_model import*\n",
        "from sklearn.preprocessing import*\n",
        "from sklearn.tree import*\n",
        "from sklearn.ensemble import*\n",
        "from sklearn.metrics import*\n",
        "from sklearn.neighbors import*\n",
        "from sklearn.svm import*\n",
        "from sklearn.naive_bayes import*"
      ],
      "metadata": {
        "id": "4KUQ4-1zO3nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get data form above github"
      ],
      "metadata": {
        "id": "7HkQNaz3PK4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HR_DATA_URL = \"https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/HR%20Analytics/ibm-hr-analytics-employee-attrition-performance.zip\"\n",
        "hrdf = pd.read_csv(HR_DATA_URL, compression='zip')\n",
        "hrdf.head()\n"
      ],
      "metadata": {
        "id": "RbuM94PEPRQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.shape"
      ],
      "metadata": {
        "id": "Gly02VXMRfCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.info()"
      ],
      "metadata": {
        "id": "D2vsEjHdRokQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_hrdf = hrdf.isnull().sum()\n",
        "\n",
        "print(missing_hrdf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Et3tVmwQRw-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping some elements those are not imply any meaningful insights in our analysis\n",
        "\n",
        "cols_drop  = ['EmployeeCount','EmployeeNumber','Over18','StandardHours']\n",
        "hrdf = hrdf.drop(cols_drop,axis=1)\n",
        "hrdf.head()"
      ],
      "metadata": {
        "id": "ZQI-nStEpb5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in hrdf.columns:\n",
        "    print(f\"Column: {column}, Unique Values: {hrdf[column].unique()}\")"
      ],
      "metadata": {
        "id": "jbxyf_DkxUIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.duplicated().sum()\n",
        "\n",
        "print(hrdf.duplicated())"
      ],
      "metadata": {
        "id": "MwT0EVtOTRIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above info output ,there is no null data or duplicates in the dataset"
      ],
      "metadata": {
        "id": "Kci7Xz5MVl5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.describe()"
      ],
      "metadata": {
        "id": "43vb_3QZV_Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.dtypes"
      ],
      "metadata": {
        "id": "1SYtaLvTxlqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RL5UcB8vxuVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hrdf.groupby([\"Attrition\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"BusinessTravel\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"Department\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"EducationField\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"Gender\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"JobRole\"]).size())\n",
        "print('\\n')\n",
        "print(hrdf.groupby([\"MaritalStatus\"]).size())"
      ],
      "metadata": {
        "id": "W2y0CkWmYHOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']\n",
        "\n",
        "for col in categorical_columns:\n",
        "  le = LabelEncoder()\n",
        "  hrdf[col] = le.fit_transform(hrdf[col])\n"
      ],
      "metadata": {
        "id": "qqcP9J0g0waV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.head()"
      ],
      "metadata": {
        "id": "PT8z8eMb1Yu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First we can check the age wise employees count an org\n",
        "age_attrition = hrdf.groupby([\"Age\", \"Attrition\"]).size().unstack()\n",
        "age_attrition"
      ],
      "metadata": {
        "id": "sxpvhQkZYoC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above details givs us ,The age_attrition shows the number of employees who left  or stay in the company for each age group\n",
        "\n",
        "From above data **1.employees aged 30-40 have a lower attrition rate compared to** other age groups\n",
        "**2.Employees aged 45 have a higher attrition rate**"
      ],
      "metadata": {
        "id": "ge4I0D9RajLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "numerical_hrdf = hrdf.select_dtypes(include = [np.number])\n",
        "\n",
        "#calculate z_score for numerical columns\n",
        "\n",
        "z_scores = stats.zscore(numerical_hrdf)\n",
        "outliers = (z_scores > 3) | (z_scores < -3)\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "PlLACTu6e7En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for more understanding\n",
        "age_attrition.plot(kind = 'bar',stacked=True,figsize=(15,10))\n",
        "plt.title('Attrition by Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of Employees')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AuGi-s-daaz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show employee Attrition in percentage\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='Attrition',data=hrdf)\n",
        "plt.title('Attrition')\n",
        "plt.xlabel('Attrition')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K-QfmqikqwiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_bar_plot(df, column1, column2):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.subplot(1,2,1)\n",
        "  df[column1].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "  plt.title(f'{column1} Distribution')\n",
        "  plt.subplot(1,2,2)\n",
        "  sns.countplot(x=column1, hue=column2, data=df)\n",
        "  plt.title(f'{column1} vs {column2}')\n",
        "\n",
        "  plt.show()\n",
        "pie_bar_plot(hrdf,'Gender', 'Attrition')"
      ],
      "metadata": {
        "id": "enQeo1ezrL8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pie_bar_plot(hrdf,'EducationField', 'Attrition')"
      ],
      "metadata": {
        "id": "8zZvg8vqsrvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pie_bar_plot(hrdf,'JobRole', 'Attrition')"
      ],
      "metadata": {
        "id": "v37ZrDeLtAUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4ofKa49tKsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.hist(figsize=(20,20), color = 'g',alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q_dCzquwcuJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on montlly income and Attrition\n",
        "\n",
        "rate_attrition = hrdf.groupby([\"MonthlyIncome\", \"Attrition\"]).size().unstack()\n",
        "rate_attrition"
      ],
      "metadata": {
        "id": "B8bYhYDsd-kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.dtypes"
      ],
      "metadata": {
        "id": "bGEdqNDsW9IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.describe()"
      ],
      "metadata": {
        "id": "WfBFGPNqphDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_hrdf = hrdf.select_dtypes(include = [np.number])\n",
        "numerical_hrdf\n",
        "fig,ax = plt.subplots(figsize=(25,20))\n",
        "sns.heatmap(numerical_hrdf.corr(),annot=True,ax=ax)"
      ],
      "metadata": {
        "id": "wBoEZNSYqkS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here ,Joblevel,monthlyIncome is have highest correlation\n",
        "and remaining some elements have good correlation like Joblevel ,Total working experience ,Total years in company, Years in Current role,Years wtih last promotion ,years with current manager etc .\n",
        "\n",
        "and performance rating with percentage Hike is also good correlation .\n",
        "\n",
        "\n",
        "Some variables that are more related to the targetvariable attrition.\n",
        "\n",
        "EnvironmentSatisfaction,Jobinvolvment, Job levell,Job satisfaction,MonthlyIncome, Stock Optional Level,Total working years , etc ..\n"
      ],
      "metadata": {
        "id": "MjHs_7VbyXq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf[(hrdf[\"Attrition\"]== 1)] .groupby([\"EducationField\"]).size()"
      ],
      "metadata": {
        "id": "WJ7j9QQP7STe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "hrdf[(hrdf[\"Attrition\"]== 0)] .groupby([\"EducationField\"]).size()"
      ],
      "metadata": {
        "id": "0gHhZaJM7Yhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if age_attrition = 1\n",
        "hrdf[(hrdf[\"Attrition\"]== 1)] .groupby([\"EducationField\"]).size() / hrdf.groupby([\"EducationField\"]).size()"
      ],
      "metadata": {
        "id": "OZtUlk456Iz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if age_attrition = 0\n",
        "hrdf[(hrdf[\"Attrition\"]== 0)] .groupby([\"EducationField\"]).size() / hrdf.groupby([\"EducationField\"]).size()"
      ],
      "metadata": {
        "id": "nFeO1rhz8Frb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hrdf.groupby([\"Attrition\"]).size()\n",
        "hrdf.groupby(['Gender']).sum()"
      ],
      "metadata": {
        "id": "-veF_UMu837R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Above ,**we looks at the pecentage of attrited employees by education field**"
      ],
      "metadata": {
        "id": "p2PQiE9l67al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hrdf.groupby([\"Attrition\"]).size()"
      ],
      "metadata": {
        "id": "-ggXHcSP7FN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_hrdf1 = hrdf.select_dtypes(include = 'number')\n",
        "hrdf1_skewness = num_hrdf1.skew()\n",
        "print(hrdf1_skewness)"
      ],
      "metadata": {
        "id": "2E7o6O5sSjnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature selection\n",
        "\n",
        "#above heat map tells us how related the variables  to attrition.\n",
        "#we will pick the ones that have an absolute correlation value greater than 0.1 for our model\n",
        "\n",
        "#picking the features that have absolute correlation value greater than 0.1\n",
        "\n",
        "hrdf1 = hrdf[['Attrition', 'Age', 'BusinessTravel', 'EducationField', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'OverTime', 'StockOptionLevel', 'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsWithCurrManager']]\n"
      ],
      "metadata": {
        "id": "xkB4w2aMPSsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = hrdf1.drop('Attrition', axis=1)\n",
        "y = hrdf1['Attrition'] # y is target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "j_nVqT1oRmpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)"
      ],
      "metadata": {
        "id": "j_dZ6XUovT2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in x.columns:\n",
        "  if x[col].dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    x[col] = le.fit_transform(x[col])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(\"Train set:\", x_train.shape, y_train.shape)\n",
        "print(\"Test set:\", x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "h0lnwScMvSdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building logistric regression model to fit training model\n",
        "\n"
      ],
      "metadata": {
        "id": "NX9zpxO5TvoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#ValueError: could not convert string to float: 'No'\n",
        "\n",
        "\n",
        "\n",
        "LR_model = LogisticRegression(C = 1.0 ,solver = 'newton-cg', max_iter = 800,random_state = 85).fit(x_train,y_train)\n",
        "LR_model"
      ],
      "metadata": {
        "id": "g9IpDiA_TuOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xtrain_pred = LR_model.predict(x_train)\n",
        "#print(xtrain_pred)\n",
        "\n",
        "LR_Y_pred = LR_model.predict(x_test)\n",
        "print(LR_Y_pred)"
      ],
      "metadata": {
        "id": "CE2vU7HXWAlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_Acc = accuracy_score(y_test,LR_Y_pred)\n",
        "print(\"LR :\",LR_Acc)\n",
        "\n",
        "precision = precision_score(y_test,LR_Y_pred)\n",
        "recall = recall_score(y_test,LR_Y_pred)\n",
        "f1 = f1_score(y_test,LR_Y_pred)\n",
        "print('precision',precision)\n",
        "print(recall)\n",
        "print(f1)\n"
      ],
      "metadata": {
        "id": "bLs0mdYGwa8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_mat = confusion_matrix(y_test,LR_Y_pred)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "Ez0fdM6GxR0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test,LR_Y_pred)\n",
        "print(\"Classification report :\", class_report)"
      ],
      "metadata": {
        "id": "n5x4X3S8xcyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model selection\n",
        "\n",
        "models = [LinearRegression(),\n",
        "          Ridge(alpha = 0.001),\n",
        "          Lasso(alpha=0.003),\n",
        "          SVR(),\n",
        "          DecisionTreeRegressor(),\n",
        "          RandomForestRegressor(),\n",
        "          BayesianRidge(),\n",
        "          GradientBoostingRegressor(),\n",
        "          AdaBoostRegressor(base_estimator=LinearRegression())]\n",
        "\n",
        "model_names = 'LinearRegression','Ridge','Lasso','SVR','DecisionTreeRegressor','RandomForestRegressor','BayesianRidge','GradientBoostingRegressor','AdaBoostRegressor'\n",
        "model_df = pd.DataFrame(columns=['Model','MSE','R2','MeanCV'])\n",
        "for model,model_names in zip(models,model_names):\n",
        "  print(model)\n",
        "\n",
        "  model.fit(x_train,y_train)\n",
        "  pred = model.predict(x_test)\n",
        "  mse = mean_squared_error(y_test,pred,squared=False)\n",
        "  r2 = model.score(x_test,y_test)\n",
        "\n",
        "  averages = cross_val_score(model,x_train,y_train,cv=5,scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "  model_df = pd.concat([model_df,pd.DataFrame({'Model': [model_names],'MSE':mse,'R2':r2,'MeanCV': [averages]})],ignore_index=True)\n",
        "print(model_df)"
      ],
      "metadata": {
        "id": "-84D9QRzWJAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on above details  GradientBoostingRegressor  is the best model\n",
        "\n"
      ],
      "metadata": {
        "id": "fnghb0xWx_ds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}